# Model configuration
model:
  model_hub: chessbot/models/model_example.py  # Path to the model file
  model_class: ChessTransformer                      # Name of the model class
  save_path: chessbot/models/saved_model.pt    # Path to save the trained model

# Dataset configuration
dataset:
  train_path: /home/kage/chess_workspace/PGN_dataset/Dataset-new/train  # Path to training PGN dataset
  test_path: /home/kage/chess_workspace/PGN_dataset/Dataset-new/test    # Path to test PGN dataset
  samples_train: 500                                                    # Number of training sample files
  samples_test: 20                                                      # Number of test sample files
  num_threads: 20                                                       # Number of threads for dataset loading

# Training configuration
training:
  batchsize_train: 3072                 # Training batch size
  batchsize_test: 3072                  # Validation batch size
  lr: 0.0005                            # Learning rate
  warmup_lr: 0.00005                    # Initial learning rate during warmup
  warmup_iters: 200                     # Number of warmup iterations
  warmup_strategy: cos                  # Warmup strategy
  scheduler_iters: 100000               # Total scheduler steps
  num_rounds: 50                        # Number of training rounds
  optimizer: adamw                      # Optimizer
  compile: true                         # Compile the model
  amp: true                             # Enable automatic mixed precision
  grad_clip: 1.0                        # Gradient clipping norm value.

# Logging configuration
logging:
  log_every: 200                        # Log metrics every N iterations
  validation_every: 20000               # Validate the model every N iterations
  wandb: true                           # Enable logging to Weights & Biases
  wandb_project: chessbot               # W&B project name

